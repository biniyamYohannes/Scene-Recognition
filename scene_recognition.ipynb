{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, shutil\n",
    "from os import walk\n",
    "import tensorflow as tf\n",
    "from keras import models, layers, optimizers, regularizers, callbacks, preprocessing\n",
    "from keras.applications import VGG16, Xception\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataframes holding the image paths and classes\n",
    "\n",
    "datadir = '/home/biniyam.yohannes/dlproject/data/201/'\n",
    "labels_dir = '/home/biniyam.yohannes/dlproject/train_data_201.csv'\n",
    "data = pd.read_csv(labels_dir)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "classes = 201\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a generator\n",
    "\n",
    "img_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        samplewise_center=True,\n",
    "        samplewise_std_normalization=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to select random batches of data from the dataset\n",
    "\n",
    "def get_random_batch(sample_size):\n",
    "    data_sample = data.sample(n=sample_size)\n",
    "    \n",
    "    train_generator = img_datagen.flow_from_dataframe(\n",
    "        data_sample, color_mode=\"rgb\", x_col=\"Path\", y_col=\"Class\",\n",
    "        target_size=(224, 224), class_mode=\"categorical\",\n",
    "        subset=\"training\",batch_size=batch_size)\n",
    "    steps_per_epoch = len(train_generator)\n",
    "    \n",
    "    # Recommend to convert generator to tf.data.Dataset for mirroredstrategy use.\n",
    "    train_data = tf.data.Dataset.from_generator(\n",
    "         lambda: train_generator,\n",
    "         output_types=(tf.float32, tf.float32),\n",
    "         output_shapes=([None, input_shape[0], input_shape[1], input_shape[2]], # Image Shape\n",
    "                        [None, classes]))                                       # Label Shape\n",
    "    \n",
    "    train_data_c = train_data.cache()\n",
    "    \n",
    "    return train_data_c, steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model 1 - VGG16\n",
    "\n",
    "# def get_model():\n",
    "#     conv_base = VGG16(\n",
    "#         weights='imagenet',\n",
    "#         include_top=False,\n",
    "#         input_shape=input_shape)\n",
    "#     conv_base.trainable = False\n",
    "\n",
    "#     model = models.Sequential()\n",
    "#     model.add(conv_base)\n",
    "#     model.add(layers.Flatten())\n",
    "#     model.add(layers.Dense(classes, activation='relu'))  # did you mean to have 'classes' neurons in this layer?\n",
    "#     model.add(layers.Dense(classes, activation='softmax'))\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model 2 - VGG16 + Fine-tuning\n",
    "\n",
    "# def get_model():\n",
    "    \n",
    "#     conv_base = VGG16(\n",
    "#         weights='imagenet',\n",
    "#         include_top=False,\n",
    "#         input_shape=input_shape)\n",
    "    \n",
    "#     set_trainable = False\n",
    "    \n",
    "#     for layer in conv_base.layers:\n",
    "#         if layer.name == 'block5_conv1':\n",
    "#             set_trainable = True\n",
    "#         if set_trainable:\n",
    "#             layer.trainable = True\n",
    "#         else:\n",
    "#             layer.trainable = False\n",
    "\n",
    "#     model = models.Sequential()\n",
    "#     model.add(conv_base)\n",
    "#     model.add(layers.Flatten())\n",
    "#     model.add(layers.Dense(1024, activation='relu'))\n",
    "#     model.add(layers.Dense(classes, activation='softmax'))\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3 - Xception\n",
    "\n",
    "def get_model():\n",
    "    conv_base = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=input_shape)\n",
    "    conv_base.trainable = False\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(conv_base)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(classes, activation='relu'))  # did you mean to have 'classes' neurons in this layer?\n",
    "    model.add(layers.Dense(classes, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to train a given model\n",
    "\n",
    "def train_model(epochs, sample_size, checkpoints_path):\n",
    "    train_batch, steps = get_random_batch(sample_size)\n",
    "    epoch = 1\n",
    "    for _ in range(epochs):\n",
    "        print(\"Epochs: {}/{}\".format(epoch, epochs))\n",
    "        epoch += 1\n",
    "        model.fit(\n",
    "            train_batch,\n",
    "            epochs=1,\n",
    "            steps_per_epoch=steps\n",
    "        )\n",
    "        model.save(checkpoints_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up tensorflow mirrored strategy to split batches among virtual gpus.\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy(\n",
    "     # devices=[\"/gpu:0\"], # ,\"/gpu:1\", \"/gpu:2\", \"/gpu:3\"\n",
    "     # cross_device_ops = tf.distribute.HierarchicalCopyAllReduce()\n",
    ")\n",
    "\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select if you want to continue training an existing model or define a new one\n",
    "\n",
    "model_path = \"/home/biniyam.yohannes/dlproject/xception_checkpoint\"\n",
    "\n",
    "with strategy.scope():\n",
    "    if os.path.exists(model_path):\n",
    "        model = models.load_model(model_path)\n",
    "        print(\"Previous Model Loaded.\")\n",
    "    else:\n",
    "        model = get_model()\n",
    "\n",
    "        model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer=optimizers.Adam(lr=0.001),\n",
    "            metrics=['accuracy',\n",
    "                     tf.keras.metrics.TopKCategoricalAccuracy(\n",
    "                         k=5, name=\"top_5_acc\")])\n",
    "        \n",
    "        print(\"New Model Created.\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "with strategy.scope():\n",
    "    model.compile(\n",
    "                loss='categorical_crossentropy',\n",
    "                optimizer=optimizers.SGD(lr=0.0001, momentum = .9),\n",
    "                metrics=['accuracy',\n",
    "                         tf.keras.metrics.TopKCategoricalAccuracy(\n",
    "                             k=5, name=\"top_5_acc\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to select random batches of data and prepare it for validation\n",
    "\n",
    "def get_validation_sample_acc(sample_size):\n",
    "    valid_data_sample = valid_data_df.sample(n=sample_size, random_state = 47)\n",
    "    \n",
    "    valid_generator = img_datagen.flow_from_dataframe(\n",
    "        valid_data_sample, color_mode=\"rgb\", x_col=\"Path\", y_col=\"Class\",\n",
    "        target_size=(224, 224), class_mode=\"categorical\",batch_size=batch_size)\n",
    "    valid_steps = len(valid_generator)\n",
    "    \n",
    "    valid_data = tf.data.Dataset.from_generator(\n",
    "     lambda: valid_generator,\n",
    "     output_types=(tf.float32, tf.float32),\n",
    "     output_shapes=([None, input_shape[0], input_shape[1], input_shape[2]], # Image Shape\n",
    "                    [None, classes]))                                       # Label Shape\n",
    "    \n",
    "    val_eval = model.evaluate(valid_data, steps=valid_steps)\n",
    "    \n",
    "    return val_eval[1] # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the validation data and convert it into a dataframe\n",
    "\n",
    "valid_dir = '/home/biniyam.yohannes/dlproject/valid_data_201.csv'\n",
    "valid_data_df = pd.read_csv(valid_dir)\n",
    "valid_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate validation accuracy on a sample with size 20000\n",
    "\n",
    "get_validation_sample_acc(20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on 15 random data batches, with 10 epochs for every batch \n",
    "\n",
    "%%notify\n",
    "best_path = \"/home/biniyam.yohannes/dlproject/xception_model_best\"\n",
    "checkpoints_path = \"/home/biniyam.yohannes/dlproject/xception_checkpoint\"\n",
    "epochs_per_batch = 10\n",
    "batches = 15\n",
    "batch_sample_size = 102400\n",
    "valid_sample_size = 20000\n",
    "best_acc = .43\n",
    "\n",
    "for _ in range(batches):\n",
    "    batch = 1\n",
    "    print(\"Batches: {}/{}\".format(batch, batches))\n",
    "    batch += 1\n",
    "    train_model(epochs_per_batch, batch_sample_size, checkpoints_path)\n",
    "    val_acc = get_validation_sample_acc(valid_sample_size)\n",
    "    print(\"Val Accuracy: {:10.4}\".format(val_acc))\n",
    "    if (val_acc-best_acc) > .005:\n",
    "        best_acc = val_acc\n",
    "        model.save(best_path)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/home/biniyam.yohannes/dlproject/models/xception_model\"\n",
    "model.save(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and sort the class label names\n",
    "\n",
    "class_labels = ['cockpit', 'corn_field', 'supermarket', 'igloo', 'swamp', 'restaurant_kitchen', 'iceberg', 'botanical_garden', 'campsite', 'chalet', 'engine_room', 'attic', 'veranda', 'food_court', 'aqueduct', 'medina', 'pond', 'yard', 'valley', 'forest_path', 'beauty_salon', 'ice_skating_rink', 'music_studio', 'candy_store', 'ski_resort', 'herb_garden', 'banquet_hall', 'market', 'hotel_room', 'bridge', 'mansion', 'watering_hole', 'butchers_shop', 'shopfront', 'swimming_pool', 'home_office', 'schoolhouse', 'bakery', 'classroom', 'amphitheater', 'doorway', 'aquarium', 'cafeteria', 'forest_road', 'hospital', 'excavation', 'conference_center', 'kindergarden_classroom', 'parking_lot', 'windmill', 'hotel', 'pulpit', 'parlor', 'playground', 'raft', 'gas_station', 'kitchenette', 'butte', 'kitchen', 'rice_paddy', 'boat_deck', 'courthouse', 'kasbah', 'train_station', 'highway', 'rainforest', 'staircase', 'corridor', 'conference_room', 'creek', 'water_tower', 'desert', 'art_studio', 'ice_cream_parlor', 'wheat_field', 'reception', 'building_facade', 'plaza', 'canyon', 'hospital_room', 'coffee_shop', 'bus_interior', 'driveway', 'basement', 'bayou', 'sandbar', 'palace', 'snowfield', 'bamboo_forest', 'marsh', 'islet', 'underwater', 'office_building', 'fountain', 'motel', 'shed', 'subway_station', 'crevasse', 'dining_room', 'hot_spring', 'residential_neighborhood', 'sea_cliff', 'restaurant_patio', 'runway', 'ballroom', 'field', 'racecourse', 'castle', 'laundromat', 'pasture', 'dam', 'volcano', 'fire_escape', 'clothing_store', 'track', 'inn', 'viaduct', 'vegetable_garden', 'sky', 'nursery', 'jail_cell', 'ocean', 'stage', 'alley', 'assembly_line', 'bowling_alley', 'living_room', 'patio', 'martial_arts_gym', 'temple', 'topiary_garden', 'church', 'shoe_shop', 'boxing_ring', 'galley', 'game_room', 'pagoda', 'orchard', 'waiting_room', 'shower', 'courtyard', 'slum', 'gift_shop', 'ski_slope', 'arch', 'formal_garden', 'crosswalk', 'train_railway', 'mountain', 'rope_bridge', 'restaurant', 'golf_course', 'cathedral', 'amusement_park', 'stadium', 'dorm_room', 'garbage_dump', 'railroad_track', 'closet', 'bar', 'monastery', 'picnic_area', 'boardwalk', 'airport_terminal', 'auditorium', 'lobby', 'dock', 'apartment_building', 'basilica', 'fairway', 'mountain_snowy', 'bedroom', 'ruin', 'skyscraper', 'coast', 'harbor', 'trench', 'mausoleum', 'phone_booth', 'pavilion', 'museum', 'rock_arch', 'lighthouse', 'art_gallery', 'locker_room', 'dinette', 'pantry', 'television_studio', 'abbey', 'river', 'wind_farm', 'fire_station', 'construction_site', 'tower', 'baseball_field', 'cemetery', 'tree_farm', 'bookstore', 'cottage_garden', 'office', 'badlands']\n",
    "class_labels.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and show an example image\n",
    "\n",
    "img = preprocessing.image.load_img(\n",
    "    \"/home/biniyam.yohannes/dlproject/data/201/ocean/ocean&4655.jpg\",\n",
    "    color_mode='rgb', target_size=(224,224)\n",
    ")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the label of the image\n",
    "\n",
    "img_array = preprocessing.image.img_to_array(img)\n",
    "img_datagen.standardize(img_array)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "prediction = model.predict(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort and select the the top-5 preidctions\n",
    "\n",
    "top_5 = sorted(range(len(prediction[0])), key=lambda i: prediction[0][i], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print the top-5 predictions\n",
    "\n",
    "for i in top_5:\n",
    "    print(class_labels[i])\n",
    "    print(\"Probability: {:10.4}%\".format(prediction[0][i]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the performance on the test dataset\n",
    "\n",
    "test_dir = '/home/biniyam.yohannes/dlproject/test_data_201.csv'\n",
    "test_data_df = pd.read_csv(test_dir)\n",
    "test_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test dataset\n",
    "\n",
    "test_data_sample = test_data_df.sample(n=20000, random_state=47)\n",
    "\n",
    "test_generator = img_datagen.flow_from_dataframe(\n",
    "    test_data_sample, color_mode=\"rgb\", x_col=\"Path\", y_col=\"Class\",\n",
    "    target_size=(224, 224), class_mode=\"categorical\",batch_size=batch_size)\n",
    "test_steps = len(test_generator)\n",
    "\n",
    "test_data = tf.data.Dataset.from_generator(\n",
    " lambda: test_generator,\n",
    " output_types=(tf.float32, tf.float32),\n",
    " output_shapes=([None, input_shape[0], input_shape[1], input_shape[2]], # Image Shape\n",
    "                [None, classes]))                                       # Label Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the basic VGG-16 model and evaluate its performance \n",
    "\n",
    "model_path = \"/home/biniyam.yohannes/dlproject/models/VGG16_pretrained_model\"\n",
    "\n",
    "with strategy.scope():\n",
    "    model = models.load_model(model_path)\n",
    "    \n",
    "model.evaluate(test_data, steps=test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the fine-tuned VGG-16 model and evaluate its performance \n",
    "\n",
    "model_path = \"/home/biniyam.yohannes/dlproject/models/VGG16_finetuned_model\"\n",
    "\n",
    "with strategy.scope():\n",
    "    model = models.load_model(model_path)\n",
    "    \n",
    "model.evaluate(test_data, steps=test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the basic Xception model and evaluate its performance \n",
    "\n",
    "model_path = \"/home/biniyam.yohannes/dlproject/models/xception_model\"\n",
    "\n",
    "with strategy.scope():\n",
    "    model = models.load_model(model_path)\n",
    "    \n",
    "model.evaluate(test_data, steps=test_steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
